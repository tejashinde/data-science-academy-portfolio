{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/fashionmnist/train-images-idx3-ubyte\n/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n/kaggle/input/fashionmnist/fashion-mnist_test.csv\n/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n/kaggle/input/fashionmnist/fashion-mnist_train.csv\n/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndata_train = pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv')\ndata_test = pd.read_csv('../input/fashionmnist/fashion-mnist_test.csv')\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows, img_cols = 28, 28\ninput_shape = (img_rows, img_cols, 1)\n\nX = np.array(data_train.iloc[:, 1:])\ny = to_categorical(np.array(data_train.iloc[:, 0]))\n\n#Here we split validation data to optimiza classifier during training\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n\n#Test data\nX_test = np.array(data_test.iloc[:, 1:])\ny_test = to_categorical(np.array(data_test.iloc[:, 0]))\n\n\n\nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\nX_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_val = X_val.astype('float32')\nX_train /= 255\nX_test /= 255\nX_val /= 255","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\n\nbatch_size = 256\nnum_classes = 10\nepochs = 100\n\n#input image dimensions\nimg_rows, img_cols = 28, 28\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 kernel_initializer='he_normal',\n                 input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(num_classes, activation='softmax'))\n","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(),\n              metrics=['accuracy'])","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":12,"outputs":[{"output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 5, 5, 64)          0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 3, 3, 128)         73856     \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 3, 3, 128)         0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 1152)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               147584    \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 241,546\nTrainable params: 241,546\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(X_val, y_val))\nscore = model.evaluate(X_test, y_test, verbose=0)","execution_count":13,"outputs":[{"output_type":"stream","text":"Train on 48000 samples, validate on 12000 samples\nEpoch 1/100\n48000/48000 [==============================] - 2s 44us/step - loss: 0.8290 - accuracy: 0.6916 - val_loss: 0.5182 - val_accuracy: 0.8143\nEpoch 2/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.5196 - accuracy: 0.8090 - val_loss: 0.4184 - val_accuracy: 0.8442\nEpoch 3/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.4425 - accuracy: 0.8401 - val_loss: 0.3707 - val_accuracy: 0.8638\nEpoch 4/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.3997 - accuracy: 0.8526 - val_loss: 0.3328 - val_accuracy: 0.8792\nEpoch 5/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.3745 - accuracy: 0.8626 - val_loss: 0.3120 - val_accuracy: 0.8854\nEpoch 6/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.3516 - accuracy: 0.8726 - val_loss: 0.3010 - val_accuracy: 0.8906\nEpoch 7/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.3327 - accuracy: 0.8777 - val_loss: 0.2964 - val_accuracy: 0.8918\nEpoch 8/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.3204 - accuracy: 0.8821 - val_loss: 0.2767 - val_accuracy: 0.8998\nEpoch 9/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.3093 - accuracy: 0.8880 - val_loss: 0.2726 - val_accuracy: 0.9007\nEpoch 10/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.3015 - accuracy: 0.8899 - val_loss: 0.2700 - val_accuracy: 0.9012\nEpoch 11/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.2910 - accuracy: 0.8927 - val_loss: 0.2690 - val_accuracy: 0.9004\nEpoch 12/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.2870 - accuracy: 0.8951 - val_loss: 0.2610 - val_accuracy: 0.9043\nEpoch 13/100\n48000/48000 [==============================] - 2s 32us/step - loss: 0.2763 - accuracy: 0.8990 - val_loss: 0.2595 - val_accuracy: 0.9027\nEpoch 14/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.2720 - accuracy: 0.9000 - val_loss: 0.2504 - val_accuracy: 0.9068\nEpoch 15/100\n48000/48000 [==============================] - 2s 36us/step - loss: 0.2665 - accuracy: 0.9017 - val_loss: 0.2523 - val_accuracy: 0.9082\nEpoch 16/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.2613 - accuracy: 0.9053 - val_loss: 0.2481 - val_accuracy: 0.9059\nEpoch 17/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.2557 - accuracy: 0.9037 - val_loss: 0.2477 - val_accuracy: 0.9087\nEpoch 18/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.2520 - accuracy: 0.9071 - val_loss: 0.2435 - val_accuracy: 0.9102\nEpoch 19/100\n48000/48000 [==============================] - 2s 36us/step - loss: 0.2461 - accuracy: 0.9072 - val_loss: 0.2344 - val_accuracy: 0.9112\nEpoch 20/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.2425 - accuracy: 0.9089 - val_loss: 0.2315 - val_accuracy: 0.9134\nEpoch 21/100\n48000/48000 [==============================] - 2s 40us/step - loss: 0.2416 - accuracy: 0.9103 - val_loss: 0.2288 - val_accuracy: 0.9143\nEpoch 22/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.2381 - accuracy: 0.9112 - val_loss: 0.2332 - val_accuracy: 0.9128\nEpoch 23/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.2381 - accuracy: 0.9122 - val_loss: 0.2311 - val_accuracy: 0.9125\nEpoch 24/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.2348 - accuracy: 0.9116 - val_loss: 0.2249 - val_accuracy: 0.9143\nEpoch 25/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.2307 - accuracy: 0.9136 - val_loss: 0.2283 - val_accuracy: 0.9143\nEpoch 26/100\n48000/48000 [==============================] - 2s 32us/step - loss: 0.2242 - accuracy: 0.9150 - val_loss: 0.2223 - val_accuracy: 0.9181\nEpoch 27/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.2246 - accuracy: 0.9156 - val_loss: 0.2281 - val_accuracy: 0.9139\nEpoch 28/100\n48000/48000 [==============================] - 2s 37us/step - loss: 0.2193 - accuracy: 0.9169 - val_loss: 0.2206 - val_accuracy: 0.9175\nEpoch 29/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.2160 - accuracy: 0.9187 - val_loss: 0.2229 - val_accuracy: 0.9175\nEpoch 30/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.2151 - accuracy: 0.9195 - val_loss: 0.2225 - val_accuracy: 0.9162\nEpoch 31/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.2152 - accuracy: 0.9193 - val_loss: 0.2181 - val_accuracy: 0.9191\nEpoch 32/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.2112 - accuracy: 0.9222 - val_loss: 0.2191 - val_accuracy: 0.9202\nEpoch 33/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.2105 - accuracy: 0.9196 - val_loss: 0.2195 - val_accuracy: 0.9186\nEpoch 34/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.2097 - accuracy: 0.9214 - val_loss: 0.2213 - val_accuracy: 0.9174\nEpoch 35/100\n48000/48000 [==============================] - 2s 38us/step - loss: 0.2052 - accuracy: 0.9238 - val_loss: 0.2180 - val_accuracy: 0.9187\nEpoch 36/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.2038 - accuracy: 0.9240 - val_loss: 0.2209 - val_accuracy: 0.9187\nEpoch 37/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.2034 - accuracy: 0.9235 - val_loss: 0.2210 - val_accuracy: 0.9170\nEpoch 38/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.2034 - accuracy: 0.9229 - val_loss: 0.2173 - val_accuracy: 0.9190\nEpoch 39/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1997 - accuracy: 0.9246 - val_loss: 0.2156 - val_accuracy: 0.9208\nEpoch 40/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1965 - accuracy: 0.9258 - val_loss: 0.2135 - val_accuracy: 0.9178\nEpoch 41/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.1991 - accuracy: 0.9245 - val_loss: 0.2283 - val_accuracy: 0.9143\nEpoch 42/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1953 - accuracy: 0.9253 - val_loss: 0.2177 - val_accuracy: 0.9178\nEpoch 43/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1955 - accuracy: 0.9267 - val_loss: 0.2233 - val_accuracy: 0.9171\nEpoch 44/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1916 - accuracy: 0.9290 - val_loss: 0.2198 - val_accuracy: 0.9195\nEpoch 45/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1941 - accuracy: 0.9265 - val_loss: 0.2170 - val_accuracy: 0.9200\nEpoch 46/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1909 - accuracy: 0.9268 - val_loss: 0.2144 - val_accuracy: 0.9202\nEpoch 47/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1889 - accuracy: 0.9273 - val_loss: 0.2141 - val_accuracy: 0.9215\nEpoch 48/100\n48000/48000 [==============================] - 2s 36us/step - loss: 0.1887 - accuracy: 0.9287 - val_loss: 0.2180 - val_accuracy: 0.9199\nEpoch 49/100\n48000/48000 [==============================] - 2s 32us/step - loss: 0.1906 - accuracy: 0.9279 - val_loss: 0.2148 - val_accuracy: 0.9208\nEpoch 50/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1855 - accuracy: 0.9306 - val_loss: 0.2167 - val_accuracy: 0.9220\nEpoch 51/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1851 - accuracy: 0.9294 - val_loss: 0.2161 - val_accuracy: 0.9214\nEpoch 52/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1835 - accuracy: 0.9303 - val_loss: 0.2143 - val_accuracy: 0.9216\nEpoch 53/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.1788 - accuracy: 0.9322 - val_loss: 0.2218 - val_accuracy: 0.9205\nEpoch 54/100\n48000/48000 [==============================] - 2s 36us/step - loss: 0.1815 - accuracy: 0.9315 - val_loss: 0.2187 - val_accuracy: 0.9210\nEpoch 55/100\n48000/48000 [==============================] - 2s 38us/step - loss: 0.1819 - accuracy: 0.9313 - val_loss: 0.2126 - val_accuracy: 0.9220\n","name":"stdout"},{"output_type":"stream","text":"Epoch 56/100\n48000/48000 [==============================] - 2s 44us/step - loss: 0.1767 - accuracy: 0.9325 - val_loss: 0.2157 - val_accuracy: 0.9206\nEpoch 57/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.1805 - accuracy: 0.9315 - val_loss: 0.2176 - val_accuracy: 0.9208\nEpoch 58/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1776 - accuracy: 0.9317 - val_loss: 0.2176 - val_accuracy: 0.9212\nEpoch 59/100\n48000/48000 [==============================] - 2s 36us/step - loss: 0.1799 - accuracy: 0.9320 - val_loss: 0.2216 - val_accuracy: 0.9209\nEpoch 60/100\n48000/48000 [==============================] - 2s 37us/step - loss: 0.1786 - accuracy: 0.9330 - val_loss: 0.2256 - val_accuracy: 0.9171\nEpoch 61/100\n48000/48000 [==============================] - 2s 36us/step - loss: 0.1773 - accuracy: 0.9322 - val_loss: 0.2153 - val_accuracy: 0.9198\nEpoch 62/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1781 - accuracy: 0.9325 - val_loss: 0.2185 - val_accuracy: 0.9218\nEpoch 63/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.1752 - accuracy: 0.9341 - val_loss: 0.2169 - val_accuracy: 0.9237\nEpoch 64/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1776 - accuracy: 0.9317 - val_loss: 0.2179 - val_accuracy: 0.9224\nEpoch 65/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1777 - accuracy: 0.9310 - val_loss: 0.2178 - val_accuracy: 0.9214\nEpoch 66/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1730 - accuracy: 0.9351 - val_loss: 0.2208 - val_accuracy: 0.9218\nEpoch 67/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1720 - accuracy: 0.9346 - val_loss: 0.2169 - val_accuracy: 0.9224\nEpoch 68/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1715 - accuracy: 0.9351 - val_loss: 0.2162 - val_accuracy: 0.9212\nEpoch 69/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1756 - accuracy: 0.9340 - val_loss: 0.2150 - val_accuracy: 0.9210\nEpoch 70/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1686 - accuracy: 0.9348 - val_loss: 0.2154 - val_accuracy: 0.9215\nEpoch 71/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1701 - accuracy: 0.9361 - val_loss: 0.2191 - val_accuracy: 0.9208\nEpoch 72/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1704 - accuracy: 0.9353 - val_loss: 0.2120 - val_accuracy: 0.9227\nEpoch 73/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1720 - accuracy: 0.9362 - val_loss: 0.2107 - val_accuracy: 0.9228\nEpoch 74/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.1667 - accuracy: 0.9375 - val_loss: 0.2174 - val_accuracy: 0.9209\nEpoch 75/100\n48000/48000 [==============================] - 2s 36us/step - loss: 0.1689 - accuracy: 0.9357 - val_loss: 0.2142 - val_accuracy: 0.9212\nEpoch 76/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1671 - accuracy: 0.9362 - val_loss: 0.2143 - val_accuracy: 0.9246\nEpoch 77/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1662 - accuracy: 0.9377 - val_loss: 0.2185 - val_accuracy: 0.9217\nEpoch 78/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1676 - accuracy: 0.9362 - val_loss: 0.2221 - val_accuracy: 0.9204\nEpoch 79/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1680 - accuracy: 0.9368 - val_loss: 0.2168 - val_accuracy: 0.9210\nEpoch 80/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1611 - accuracy: 0.9399 - val_loss: 0.2175 - val_accuracy: 0.9230\nEpoch 81/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1651 - accuracy: 0.9366 - val_loss: 0.2246 - val_accuracy: 0.9197\nEpoch 82/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1620 - accuracy: 0.9383 - val_loss: 0.2202 - val_accuracy: 0.9211\nEpoch 83/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1655 - accuracy: 0.9373 - val_loss: 0.2161 - val_accuracy: 0.9217\nEpoch 84/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1648 - accuracy: 0.9368 - val_loss: 0.2186 - val_accuracy: 0.9216\nEpoch 85/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1631 - accuracy: 0.9379 - val_loss: 0.2163 - val_accuracy: 0.9222\nEpoch 86/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1644 - accuracy: 0.9379 - val_loss: 0.2156 - val_accuracy: 0.9230\nEpoch 87/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1616 - accuracy: 0.9389 - val_loss: 0.2143 - val_accuracy: 0.9235\nEpoch 88/100\n48000/48000 [==============================] - 2s 36us/step - loss: 0.1631 - accuracy: 0.9393 - val_loss: 0.2134 - val_accuracy: 0.9233\nEpoch 89/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1578 - accuracy: 0.9392 - val_loss: 0.2166 - val_accuracy: 0.9231\nEpoch 90/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1646 - accuracy: 0.9371 - val_loss: 0.2165 - val_accuracy: 0.9229\nEpoch 91/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.1614 - accuracy: 0.9389 - val_loss: 0.2156 - val_accuracy: 0.9236\nEpoch 92/100\n48000/48000 [==============================] - 2s 39us/step - loss: 0.1618 - accuracy: 0.9376 - val_loss: 0.2165 - val_accuracy: 0.9250\nEpoch 93/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1631 - accuracy: 0.9371 - val_loss: 0.2161 - val_accuracy: 0.9251\nEpoch 94/100\n48000/48000 [==============================] - 2s 37us/step - loss: 0.1588 - accuracy: 0.9389 - val_loss: 0.2159 - val_accuracy: 0.9224\nEpoch 95/100\n48000/48000 [==============================] - 2s 37us/step - loss: 0.1574 - accuracy: 0.9408 - val_loss: 0.2106 - val_accuracy: 0.9255\nEpoch 96/100\n48000/48000 [==============================] - 2s 36us/step - loss: 0.1598 - accuracy: 0.9390 - val_loss: 0.2122 - val_accuracy: 0.9260\nEpoch 97/100\n48000/48000 [==============================] - 2s 35us/step - loss: 0.1575 - accuracy: 0.9406 - val_loss: 0.2167 - val_accuracy: 0.9209\nEpoch 98/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1590 - accuracy: 0.9395 - val_loss: 0.2126 - val_accuracy: 0.9244\nEpoch 99/100\n48000/48000 [==============================] - 2s 34us/step - loss: 0.1551 - accuracy: 0.9417 - val_loss: 0.2165 - val_accuracy: 0.9246\nEpoch 100/100\n48000/48000 [==============================] - 2s 33us/step - loss: 0.1564 - accuracy: 0.9408 - val_loss: 0.2171 - val_accuracy: 0.9236\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":14,"outputs":[{"output_type":"stream","text":"Test loss: 0.20221616916283966\nTest accuracy: 0.9312000274658203\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}